- name: Download Files From Novogene
  hosts: localhost
  vars:
    ## Populated from inventory:
    # ------------------------------
    # batchid
    # send_to_email
    # labdata_mount
    ## ------------------------------
    ## fixed
    novogene_mount: /mnt/novogene
    labdata_mount: /mnt/labdata
    test_mode: '"{{ batchid }}" == "X200SC00000000-Z01-F001"'
    send_update_email: True
    email_folder : ~/LABEMAIL/
    email_subject: "Novogene Batch Download: {{ batchid }}"
    ##
    secrets_novogene : ~/.secrets/novagene_credentials
    secrets_usegalaxy : ~/.secrets/usegalaxy_credentials
    ##
    dir_tempdown: /home/dietpi/download_area
    ## Labsheet
    local_sheet: /home/dietpi/novogene_pipeline/samplesheet.org
    local_tsv: /home/dietpi/novogene_pipeline/samplesheet.tsv
    remote_sheet: '{{ labdata_mount }}/novogene_samplesheet.org'
    remote_tsv: '{{ labdata_mount }}/novogene_samplesheet.tsv'
    ## Do not modify vars below this line
    ## - Fixed dirs
    novogene_subdir: TEST
    working_dir : "{{ dir_tempdown }}/{{ batchid }}"
    email_chain : '{{ working_dir }}/email.chain'
    unpacked_dir : unpacked
    upload_dir : upload_to_galaxy
    ## - Envs and vars
    bioblend_env : ~/.bioblendenv
    match_fastq: 'f(ast)?q(\.gz)?'
    ansible_lock_file: /tmp/ANSIBLE_LOCK.lock
    ## -
    ansible_remote_tmp: /tmp
    ## Time stuff
    cdt : '{{ ansible_date_time }}'
    ftp_directory: '{{ cdt.date }}-{{ cdt.hour }}{{ cdt.minute }}__{{ batchid }}'
    org_timestamp: '{{ cdt.date }} {{ cdt.weekday[0:3] }} {{ cdt.hour }}:{{ cdt.minute }}'
    ## Read secrets contents
    s_usegalaxy: "{{ lookup('file', secrets_usegalaxy) }}"
    s_novogene : "{{ lookup('file', secrets_novogene) }}"
    ## Get keys: Galaxy
    usergalaxy: "{{ s_usegalaxy.split()[0] }}"
    pwdgalaxy : "{{ s_usegalaxy.split()[1] }}"
    apigalaxy : "{{ s_usegalaxy.split()[2] }}"
    ## Get keys: Novogene
    usernovo : "{{ s_novogene.split()[0] }}"
    pwdnovo  : "{{ s_novogene.split()[1] }}"
    ##
  become: no
  tasks:
  - include_tasks: playbooks/install-dependencies.yaml

  - name: Prime the working dir
    become: no
    ansible.builtin.file:
       path: '{{ working_dir }}'
       state: directory
       recurse: yes

  - name: Don't run puppeteer, install test data
    when: test_mode
    block:
    - name: Install test archive
      copy:
        src: test_data/X200SC00000000-Z01-F001.tar
        dest: '{{ working_dir }}/X200SC00000000-Z01-F001.tar'
    - name: Install test MD5
      copy:
        src: test_data/X200SC00000000-Z01-F001.MD5
        dest: '{{ working_dir }}/MD5.txt'
    - name: Install test JSON
      copy:
        src: test_data/X200SC00000000-Z01-F001.json
        dest: '{{ working_dir }}/batch.json'
    - name: Install fake email to cwd
      copy:
        src: test_data/X200SC00000000-Z01-F001.email
        dest: '{{ working_dir }}/email.txt'
    - name: Install fake email to notmuch
      shell:
        chdir: '{{ working_dir }}'
        cmd: cat email.txt | notmuch insert --folder mail

  - name: Run queued email
    include_tasks: playbooks/run-emails.yaml
    vars: {param: queued}

  - name: Set starting flags
    block:
    - name: Check value of current ansible lockfile
      shell: |
         touch {{ ansible_lock_file }};
         cat {{ ansible_lock_file }};
      register: last_task

    - name: Remove lockfile if current batch is same as last (e.g. for testing)
      file:
        path: '{{ ansible_lock_file }}'
        state: absent
      when: last_task.stdout == batchid or last_task.stdout == ""

    - name: Wait for other ansible invocations to complete
      wait_for:
        path: '{{ ansible_lock_file }}'
        state: absent
        timeout: 300

    - name: Take control of the lock file
      copy:
        dest: '{{ ansible_lock_file }}'
        content: '{{ batchid }}'

  - name: Run processing emails
    include_tasks: playbooks/run-emails.yaml
    vars: {param: processing}

  - name: Get JSON manifest
    include_tasks: playbooks/run-puppeteer.yaml

  - name: Process the archives
    include_tasks: playbooks/process-archives.yaml

  - name: Process the FASTQs
    include_tasks: playbooks/process-fastqs.yaml

  - name: Upload FASTQs to Galaxy
    include_tasks: playbooks/upload-to-galaxy.yaml

  - name: Save data to archive
    block:
    - name: Mount novogene archives rw
      shell: sudo mount -o 'remount,rw' '{{ novogene_mount }}' || sudo mount -o 'rw' '{{ novogene_mount }}'

    - name: Move Unpacked Files to Archive
      synchronize:
         archive: true
         recursive: true
         src: '{{ working_dir }}/{{ upload_dir }}/'
         dest: '{{ novogene_mount }}/{{ novogene_subdir }}/{{ batchid }}'

    - name: Move supporting files to Archive
      vars:
         from_locn : "{{ working_dir }}/{{ upload_dir }}"    ## ensure NO trailing slash
         dest_root : "{{ novogene_mount }}/{{ novogene_subdir }}"
         dest_batt : "{{ dest_root }}/{{ batchid }}"
      shell:
        chdir: '{{ working_dir }}'
        cmd: |
          mv -i -v {{ batchid }}.* {{ dest_root }}/;
          cp -v files_given.md5s {{ dest_batt }}.MD5;
          cp -v sample_ids.txt {{ dest_batt }}.IDs;
          mv -i -v {{ working_dir }}/{{ unpacked_dir }}/*Report*.zip {{ dest_batt }}.report.zip;

    - name: Unmount novogene archives
      shell: |
        sudo sync
        sudo umount '{{ novogene_mount }}'


  - name: Log data in spreadsheet
    block:
    - name: Read sample IDs again
      tags: email
      shell:
         cmd: cat '{{ working_dir }}/sample_ids.txt'
      register: sample_ids

    - name: Inline sample_ids
      tags: email
      debug:
        msg: "{{ sample_ids.stdout | split('\n') | join(', ') }}"
      register: sample_ids_inline

    - name: Append new record to local sheet
      blockinfile:
        path: '{{ local_sheet }}'
        backup: true
        marker: ": {mark} {{ batchid }} ansible"
        insertafter: EOF
        block: |
         ** DONE Upload Data:
         CLOSED: [{{ org_timestamp }}]
         :PROPERTIES:
         :BATCHNO:  {{ batchid }}
         :FILEDIR:  {{ novogene_subdir }}/{{ batchid }}
         :IDS:      {{ sample_ids_inline.msg }}
         :GALAXY:   {{ batchid }}
         :END:

    - name: Convert sheet to tabular
      shell: |
         emacs -nw -Q --batch '{{ local_sheet }}' --eval \
         '(progn (setq filename_export "{{ local_tsv }}") (goto-char 0)(org-next-block 1)(let ((org-confirm-babel-evaluate nil)) (org-ctrl-c-ctrl-c)))'

    - name: Mount lab data rw
      shell: sudo mount -o 'remount,rw' '{{ labdata_mount }}' || sudo mount -o 'rw' '{{ labdata_mount }}'

    - name: Copy over local sheet to remote
      become_user: root
      copy:
        src: '{{ local_sheet }}'
        dest: '{{ remote_sheet }}'

    - name: Copy over local tsv to remote
      become_user: root
      copy:
        src: '{{ local_tsv }}'
        dest: '{{ remote_tsv }}'

    - name: Unmount lab data
      shell: |
        sudo sync
        sudo umount '{{ labdata_mount }}'


  - name: Send final email
    include_tasks: playbooks/run-emails.yaml
    vars: {param: final}

  ## Even if killed, the lock file is removed
  post_tasks:
  - name: Remove lock file
    file:
      path: '{{ ansible_lock_file }}'
      state: absent
